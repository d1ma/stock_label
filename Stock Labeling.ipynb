{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do standard imports for Python Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add working paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "import re\n",
    "home = expanduser(\"~\")\n",
    "vc_dir = \"Dropbox/Data Scrape of VC/\"\n",
    "training_dir = \"NLP Training Set\"\n",
    "\n",
    "full_input_dir = os.path.join(home, vc_dir, training_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all labels from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = os.listdir(full_input_dir)\n",
    "full_path = [os.path.join(full_input_dir, x) for x in all_files ]\n",
    "files = [x for x in full_path if os.path.isfile(x)]\n",
    "regex = \"\\[\\[(.*?)\\]\\]\"\n",
    "labels = []\n",
    "match_objs = []\n",
    "for f in files:\n",
    "    with open(f, 'r') as in_f:\n",
    "        for m in re.finditer(regex, in_f.read()):\n",
    "            current_tag = m.group()\n",
    "            labels += [current_tag]\n",
    "            match_objs += [m]\n",
    "            \n",
    "stripped_labels = [x[2:-2] for x in labels]\n",
    "share_tags = [x.split(\":\")[0] for x in stripped_labels]\n",
    "count_tags = [x.split(\":\")[1] for x in stripped_labels]\n",
    "tags_to_count = {}\n",
    "for label in stripped_labels:\n",
    "    name, _ = label.split(\":\")\n",
    "    count = tags_to_count.get(name, 0)\n",
    "    tags_to_count[name] = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are some stats about the current labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== [Stats on the training data] =====\n",
      "Number of documents: 75\n",
      "Number of training samples: 403\n",
      "Number of unique labels: 36\n"
     ]
    }
   ],
   "source": [
    "print \"===== [Stats on the training data] =====\"\n",
    "print \"Number of documents: %i\" % len(files)\n",
    "print \"Number of training samples: %i\" % len(stripped_labels)\n",
    "print \"Number of unique labels: %i\" % len(set(share_tags))\n",
    "#print \"%s\" % \"\\n \".join([str(x) for x in sorted(tags_to_count.items(), key=lambda x: x[1])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Number Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input is a number (we assume we can extract these reliably, an assumption to be tested), an context (sliding window, sentence, and sentence parse) from which we can come up with features to find a numerican representation for the number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tagged_file import *\n",
    "tfiles = read_directory(full_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16 numbers, 5 tags, 6 tagged numbers), (4 numbers, 5 tags, 4 tagged numbers), (7 numbers, 5 tags, 6 tagged numbers), (20 numbers, 10 tags, 11 tagged numbers), (11 numbers, 7 tags, 5 tagged numbers), (14 numbers, 6 tags, 8 tagged numbers), (12 numbers, 9 tags, 7 tagged numbers), (16 numbers, 5 tags, 7 tagged numbers), (10 numbers, 6 tags, 5 tagged numbers), (33 numbers, 6 tags, 8 tagged numbers), (21 numbers, 6 tags, 4 tagged numbers)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "non_matching_files = filter(lambda f: len(f.tags) != len(f.tagged_numbers()), tfiles)\n",
    "print non_matching_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "matches = [match for match in re.finditer(r'\\d+(?:,\\d+)+', tfiles[1].raw_clean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 1304)\n",
      "['[[Common Shares:13,500,000]]', '[[Preferred Shares:8,312,785]]', '[[Series A1 Preferred Shares:436,507]]', '[[Series A2 Preferred Shares:2,541,152]]', '[[Series B Preferred Shares:2,824,209]]', '[[Series C Preferred Shares:2,510,917]]']\n"
     ]
    }
   ],
   "source": [
    "m = matches[0]\n",
    "print m.span()\n",
    "print [t.group() for t in tfiles[1].tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1304, 1418, 1542, 1695, 1930, 2083]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.raw_clean[1200: 1400]\n",
    "first.tag_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting Sentence Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize each document by sentences, label each sentence as interesting or not (it's interesting if it has tags) and vectorize by three features. This will be used as training data for our decision tree for whether a sentence is interesting or not. \n",
    "\n",
    "Currently each sentence has three features that the decision tree will use. \n",
    "- Contains a number with commas\n",
    "- Sentence Length\n",
    "- Contains the word 'stock' or 'share'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10057 sentences\n",
      " 179 are interesting\n"
     ]
    }
   ],
   "source": [
    "from sentence import *\n",
    "sentence_objs = []\n",
    "features = [ContainsCommaNumber, SentenceLength, ContainsStockOrShare]\n",
    "\n",
    "for f in files:\n",
    "    with open(f, 'r') as in_f:\n",
    "        raw_text = filter_ascii(in_f.read())\n",
    "        \n",
    "        # Create sentence objects: see sentence.py for the way this is done\n",
    "        for s in parser.tokenize(raw_text):\n",
    "            sentence_objs += [Sentence(s)]\n",
    "\n",
    "\n",
    "sentence_vecs = [s.to_vector(features) for s in sentence_objs]\n",
    "output_labels = [s.is_interesting_as_int() for s in sentence_objs]\n",
    "print \"Processed %i sentences\" % len(sentence_objs)\n",
    "print \" %i are interesting\" % output_labels.count(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== [Training report] ======\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6619\n",
      "          1       0.94      0.92      0.93       119\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6738\n",
      "\n",
      "[[6612    7]\n",
      " [   9  110]]\n",
      "====== [Test report] =====\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3259\n",
      "          1       0.76      0.78      0.77        60\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3319\n",
      "\n",
      "[[3244   15]\n",
      " [  13   47]]\n"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "from sklearn import tree, cross_validation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "\n",
    "v_train, v_test, out_train, out_test, obj_train, obj_test = cross_validation.train_test_split(sentence_vecs, output_labels, sentence_objs, test_size=.33, random_state=0)\n",
    "clf = clf.fit(v_train, out_train)\n",
    "out_train_pred = clf.predict(v_train)\n",
    "out_test_pred = clf.predict(v_test)\n",
    "\n",
    "print \"====== [Training report] ======\"\n",
    "print classification_report(out_train, out_train_pred)\n",
    "cm_train = confusion_matrix(out_train, out_train_pred)\n",
    "# pl.matshow(cm_train)\n",
    "# pl.colorbar()\n",
    "# pl.show()\n",
    "print cm_train\n",
    "\n",
    "print \"====== [Test report] =====\"\n",
    "print classification_report(out_test, out_test_pred)\n",
    "cm_test = confusion_matrix(out_test, out_test_pred)\n",
    "# pl.matshow(cm_test)\n",
    "# pl.colorbar()\n",
    "# pl.show()\n",
    "print cm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_train_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-510bd847a9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtogether_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtogether_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfalse_neg_train_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtogether_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfalse_neg_test_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtogether_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_train_pred' is not defined"
     ]
    }
   ],
   "source": [
    "together_train = zip(out_train_pred, out_train)\n",
    "together_test = zip(out_test_pred, out_test)\n",
    "\n",
    "false_neg_train_i = [i for i,x  in enumerate(together_train) if (x[0] == 0 and x[1] == 1)]\n",
    "false_neg_test_i = [i for i, x in enumerate(together_test) if (x[0] == 0 and x[1] == 1)]\n",
    "\n",
    "false_neg_train = [str(obj_train[i]) for i in false_neg_train_i]\n",
    "false_neg_test = [str(obj_test[i]) for i in false_neg_test_i]\n",
    "\n",
    "print \"== Train ==\"\n",
    "print \"\\n-------\\n\".join(false_neg_train)\n",
    "\n",
    "print \"--------------------------------------------------\"\n",
    "print \"== Test ==\"\n",
    "print \"\\n-------\\n\".join(false_neg_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Interesting Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize each sentence, labelling it as interesting or not. Doing it using classification ('Interesting', 'Not') is a better long term approach because it allows for future labels to be added in addition to the stock data labelling. This might require new sentence level features to be added to `sentence.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Small Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching the labels within documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = \"The Corporation will have the authority to issue 14,000,000[[Total Shares:14,000,000]] shares of capital stock, $0.0001 par value per share, of which 10,000,000[[Common Shares:10,000,000]] shares will be Common Stock and of which 4,000,000[[Preferred Shares:4,000,000]] shares will be Preferred Stock.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 133, 184]\n",
      "The Corporation will have the authority to issue 14,000,000 shares of capital stock, $0.0001 par value per share, of which 10,000,000 shares will be Common Stock and of which 4,000,000 shares will be Preferred Stock.\n",
      "['14,000,000', '10,000,000', ' 4,000,000']\n"
     ]
    }
   ],
   "source": [
    "regex = \"\\[\\[(.*?)\\]\\]\"\n",
    "running_length = 0\n",
    "spans = []\n",
    "for m in re.finditer(regex, s):\n",
    "    sp = m.span()\n",
    "    adjusted_pos = sp[0] - running_length\n",
    "    spans += [adjusted_pos]\n",
    "    running_length += sp[1] - sp[0]\n",
    "\n",
    "print spans\n",
    "without_tags = re.sub(regex, \"\", s)\n",
    "print without_tags\n",
    "print [without_tags[(x-10): x] for x in spans]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[Preferred Shares:4,000,000]]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insertChars(s, c, *indeces)\n",
    "    \"\"\"Insert character `c` at `indeces` in the string `s`\"\"\"\n",
    "    splt = lambda s, i, : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc|de|f|ghijk'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Tokenizing documents by sentences and matching integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "parser = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_paragraph = \"\"\"\n",
    "RTICLE IV\n",
    "Effective upon filing of this Amended and Restated Certificate of Incorporation with the Delaware Secretary of State, and prior to the issuance of any shares of Preferred Stock each currently outstanding share of Common Stock will be converted and reconstituted into 8.78204 shares of Common Stock of the Corporation (the “Stock Split”). No fractional shares or scrip representing fractional shares will be issued in connection with such Stock Split. If, after the aforementioned aggregation, the Stock Split would result in the issuance of any fractional share, the Corporation shall, in lieu of issuing any fractional share, pay cash equal to the product of such fraction multiplied by the Common Stock’s fair market value (as determined by the Board of Directors) on the date of conversion. All numbers of shares, and all amounts stated on a per share basis, contained in this Amended and Restated Certificate of Incorporation, are stated after giving effect to such Stock Split and no further adjustment shall be made as a consequence of such Stock Split.\n",
    "The Corporation will have the authority to issue 14,000,000[[Total Shares:14,000,000]] shares of capital stock, $0.0001 par value per share, of which 10,000,000[[Common Shares:10,000,000]] shares will be Common Stock and of which 4,000,000[[Preferred Shares:4,000,000]] shares will be Preferred Stock.\n",
    "11 7^1901? v5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "filter_ascii = lambda s: filter(lambda x: x in string.printable, s)\n",
    "clean_par = filter_ascii(sample_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = parser.tokenize(sample_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It's notable that the parser works pretty well. For instance, it does not split on the \".\" in \"$0.0001 per share\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RTICLE IV\n",
      "Effective upon filing of this Amended and Restated Certificate of Incorporation with the Delaware Secretary of State, and prior to the issuance of any shares of Preferred Stock each currently outstanding share of Common Stock will be converted and reconstituted into 8.78204 shares of Common Stock of the Corporation (the “Stock Split”).\n",
      " ------ \n",
      "No fractional shares or scrip representing fractional shares will be issued in connection with such Stock Split.\n",
      " ------ \n",
      "If, after the aforementioned aggregation, the Stock Split would result in the issuance of any fractional share, the Corporation shall, in lieu of issuing any fractional share, pay cash equal to the product of such fraction multiplied by the Common Stock’s fair market value (as determined by the Board of Directors) on the date of conversion.\n",
      " ------ \n",
      "All numbers of shares, and all amounts stated on a per share basis, contained in this Amended and Restated Certificate of Incorporation, are stated after giving effect to such Stock Split and no further adjustment shall be made as a consequence of such Stock Split.\n",
      " ------ \n",
      "The Corporation will have the authority to issue 14,000,000[[Total Shares:14,000,000]] shares of capital stock, $0.0001 par value per share, of which 10,000,000[[Common Shares:10,000,000]] shares will be Common Stock and of which 4,000,000[[Preferred Shares:4,000,000]] shares will be Preferred Stock.\n",
      " ------ \n",
      "11 7^1901?\n",
      " ------ \n",
      "v5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\n ------ \\n\".join(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMPY Scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 1)\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "flat_v = np.array([1, 2, 3])\n",
    "tall_v = np.array([[1], [2], [3]])\n",
    "reshape_v = tall_v.reshape(-1)\n",
    "print flat_v.shape\n",
    "print tall_v.shape\n",
    "print reshape_v.shape[0]\n",
    "print flat_v.reshape(-1).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14,000,000',\n",
       " '14,000,000',\n",
       " '10,000,000',\n",
       " '10,000,000',\n",
       " '4,000,000',\n",
       " '4,000,000']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_regex = r'\\d+(?:,\\d+)+'\n",
    "re.findall(integer_regex, sample_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrticle iv\\neffective upon filing of this amended and restated certificate of incorporation with the delaware secretary of state, and prior to the issuance of any shares of preferred stock each currently outstanding share of common stock will be converted and reconstituted into 8.78204 shares of common stock of the corporation (the \\xe2\\x80\\x9cstock split\\xe2\\x80\\x9d). no fractional shares or scrip representing fractional shares will be issued in connection with such stock split. if, after the aforementioned aggregation, the stock split would result in the issuance of any fractional share, the corporation shall, in lieu of issuing any fractional share, pay cash equal to the product of such fraction multiplied by the common stock\\xe2\\x80\\x99s fair market value (as determined by the board of directors) on the date of conversion. all numbers of shares, and all amounts stated on a per share basis, contained in this amended and restated certificate of incorporation, are stated after giving effect to such stock split and no further adjustment shall be made as a consequence of such stock split.\\nthe corporation will have the authority to issue 14,000,000[[total shares:14,000,000]] shares of capital stock, $0.0001 par value per share, of which 10,000,000[[common shares:10,000,000]] shares will be common stock and of which 4,000,000[[preferred shares:4,000,000]] shares will be preferred stock.\\n11 7^1901? v5\\n'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paragraph.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0, 53,  1]), array([ 0, 17,  1]), array([ 0, 56,  1]), array([ 0, 45,  1]), array([ 3, 35,  1]), array([0, 2, 0]), array([0, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "from sentence import * \n",
    "features = [ContainsCommaNumber, SentenceLength, ContainsStockOrShare]\n",
    "sentences = [filter_ascii(s) for s in sentences]\n",
    "sent_objs = [Sentence(s) for s in sentences]\n",
    "#print sent_objs\n",
    "#print [s.is_interesting() for s in sent_objs]\n",
    "print [s.to_vector(features) for s in sent_objs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
